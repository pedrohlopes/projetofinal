{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "bMYFauN4_fqv",
    "outputId": "c88aee7e-630f-477e-dd81-f4e9c3d5f63b"
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import h5py\n",
    "import json\n",
    "import librosa\n",
    "from librosa.core import resample\n",
    "import pyrubberband as pyrb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubberband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "VqvvfLBK-3HH",
    "outputId": "caf3a6e8-de70-477b-91cb-6e50e422aad3"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "print(tf.__version__)\n",
    "print(tf.test.gpu_device_name())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hkz5MFpb-xf8"
   },
   "outputs": [],
   "source": [
    "#musdb in hand\n",
    "import musdb\n",
    "#mus = musdb.DB('/home/pedro.lopes/data/dataset/musdb18')\n",
    "mus = musdb.DB('/home/pedro.lopes/data/dataset/musdb18hq',is_wav=True)\n",
    "mus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,t,stft_data = signal.stft(mus[0].audio[:,0] + mus[0].audio[:,1])\n",
    "log_stft = np.log(np.abs(stft_data)+1e-7)\n",
    "plt.pcolormesh(log_stft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export MEDLEYDB_PATH=\"nfs/home/pedro.lopes/data/dataset/MedleyDB_V2/V2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "%cd /home/pedro.lopes/data/dataset/MedleyDB_V2/V2/\n",
    "names = glob(\"*\")\n",
    "%cd /home/pedro.lopes/pf/code\n",
    "import medleydb as mdb\n",
    "vocal_paths =[]\n",
    "medley_path = '/home/pedro.lopes/data/dataset/MedleyDB_V2/V2/'\n",
    "instruments = ['male speaker','female speaker','female singer', 'male singer','vocalists','male rapper','female rapper','male screamer','female screamer']\n",
    "mtrack_generator = mdb.load_all_multitracks()\n",
    "medley_vocal_audios = []\n",
    "medley_instrumental_audios =[]\n",
    "medley_complete_audios=[]\n",
    "for name in names:\n",
    "    track = mdb.MultiTrack(name)\n",
    "    track_vocal_paths =[]\n",
    "    track_instrumental_paths = []\n",
    "    path = medley_path + name +'/' + name +'_MIX'+ '.wav'\n",
    "    directory = medley_path + name +'/' + name + '_STEMS/'\n",
    "    %cd $directory\n",
    "    stem_paths = glob(\"*.wav\")\n",
    "    mix_audio,sr = librosa.load(path,sr=None)\n",
    "    vocal_audio = np.zeros_like(mix_audio)\n",
    "    instrumental_audio = np.zeros_like(mix_audio)\n",
    "    for key, stem in track.stems.items():\n",
    "        is_vocal=True\n",
    "        for stem_instrument in stem.instrument:\n",
    "            if stem_instrument not in instruments:\n",
    "                is_vocal=False\n",
    "        if is_vocal:\n",
    "            print(stem.instrument)\n",
    "            vocal_path = name + '_STEM_' + '{:02}'.format(stem.stem_idx) + '.wav'\n",
    "            y,sr = librosa.load(vocal_path,sr=None)\n",
    "            if sr!=44100:\n",
    "                print(sr)\n",
    "                y = resample(y,sr,44100)\n",
    "            vocal_audio+=y\n",
    "            track_vocal_paths.append(vocal_path)\n",
    "    track_instrumental_paths = [x for x in stem_paths if x not in track_vocal_paths]\n",
    "    for instrumental_path in track_instrumental_paths:\n",
    "        y,sr = librosa.load(instrumental_path,sr=None)\n",
    "        if sr!=44100:\n",
    "            y = resample(y,sr,44100)\n",
    "        instrumental_audio+=y\n",
    "    if vocal_audio.any():\n",
    "        medley_vocal_audios.append(vocal_audio)\n",
    "        medley_instrumental_audios.append(instrumental_audio)\n",
    "        medley_complete_audios.append(vocal_audio + instrumental_audio)\n",
    "\n",
    "\n",
    "\n",
    "print(str(len(medley_vocal_audios)) + \" Musicas com vocal carregadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export MEDLEYDB_PATH=\"nfs/home/pedro.lopes/data/dataset/MedleyDB_V3/\"\n",
    "%cd /home/pedro.lopes/data/dataset/MedleyDB_V3/\n",
    "names = glob(\"*\")\n",
    "%cd /home/pedro.lopes/pf/code\n",
    "import medleydb as mdb\n",
    "vocal_paths =[]\n",
    "medley_path = '/home/pedro.lopes/data/dataset/MedleyDB_V3/'\n",
    "instruments = ['male speaker','female speaker','female singer', 'male singer','vocalists','male rapper','female rapper','male screamer','female screamer']\n",
    "mtrack_generator = mdb.load_all_multitracks()\n",
    "medley3_vocal_audios = []\n",
    "medley3_instrumental_audios =[]\n",
    "medley3_complete_audios=[]\n",
    "for name in names:\n",
    "    try:\n",
    "        track = mdb.MultiTrack(name)\n",
    "    except:\n",
    "        print('nao achei metadado: '+ name)\n",
    "        continue\n",
    "    track_vocal_paths =[]\n",
    "    track_instrumental_paths = []\n",
    "    path = medley_path + name +'/' + name + '_STEMS/' + name + '_STEM_01.wav'\n",
    "    directory = medley_path + name +'/' + name + '_STEMS/'\n",
    "    %cd $directory\n",
    "    stem_paths = glob(\"*.wav\")\n",
    "    mix_audio,sr = librosa.load(path,sr=None)\n",
    "    if sr!=44100:\n",
    "        print(sr)\n",
    "        mix_audio = resample(mix_audio,sr,44100)\n",
    "    vocal_audio = np.zeros_like(mix_audio)\n",
    "    instrumental_audio = np.zeros_like(mix_audio)\n",
    "    for key, stem in track.stems.items():\n",
    "        is_vocal=True\n",
    "        for stem_instrument in stem.instrument:\n",
    "            if stem_instrument not in instruments:\n",
    "                is_vocal=False\n",
    "        if is_vocal:\n",
    "            print(stem.instrument)\n",
    "            vocal_path = name + '_STEM_' + '{:02}'.format(stem.stem_idx) + '.wav'\n",
    "            y,sr = librosa.load(vocal_path,sr=None)\n",
    "            if sr!=44100:\n",
    "                print(sr)\n",
    "                y = resample(y,sr,44100)\n",
    "            try:\n",
    "                vocal_audio+=y\n",
    "            except:\n",
    "                print('Não consegui vocal: ' + vocal_path)\n",
    "                pass\n",
    "            track_vocal_paths.append(vocal_path)\n",
    "    track_instrumental_paths = [x for x in stem_paths if x not in track_vocal_paths]\n",
    "    for instrumental_path in track_instrumental_paths:\n",
    "        y,sr = librosa.load(instrumental_path,sr=None)\n",
    "        if sr!=44100:\n",
    "            y = resample(y,sr,44100)\n",
    "        try:\n",
    "            instrumental_audio+=y\n",
    "            \n",
    "                \n",
    "                \n",
    "        except:\n",
    "            print('Não consegui instrumental: ' + instrumental_path)\n",
    "            pass\n",
    "    if vocal_audio.any():\n",
    "        medley3_vocal_audios.append(vocal_audio)\n",
    "        medley3_instrumental_audios.append(instrumental_audio)\n",
    "        medley3_complete_audios.append(vocal_audio + instrumental_audio)\n",
    "\n",
    "\n",
    "\n",
    "print(str(len(medley3_vocal_audios)) + \" Musicas com vocal carregadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/pedro.lopes/data/dataset/MedleyDB_V3/\n",
    "track2 = mdb.MultiTrack(name)\n",
    "track2._meta_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,sr = librosa.load('../audio_data/train/sample_1310_-1_acc.wav',sr=None)\n",
    "ipd.Audio(y,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = pyrb.pitch_shift(y=y,sr=sr,n_steps=-8,rbargs={'--formant': '-F'})\n",
    "ipd.Audio(out,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccmixter_path = '/home/pedro.lopes/data/dataset/ccmixter_corpus/'\n",
    "%cd $ccmixter_path\n",
    "names = glob('*')\n",
    "names.remove('README')\n",
    "ccmixter_vocal_audios = []\n",
    "ccmixter_instrumental_audios = []\n",
    "ccmixter_complete_audios = []\n",
    "for name in names:\n",
    "    directory = ccmixter_path + name + '/'\n",
    "    instrumental_path = directory + 'source-01.wav'\n",
    "    vocal_path = directory + 'source-02.wav'\n",
    "    mix_path = directory + 'mix.wav'\n",
    "    y,sr = librosa.load(vocal_path,sr=None)\n",
    "    ccmixter_vocal_audios.append(y)\n",
    "    y,sr = librosa.load(instrumental_path,sr=None)\n",
    "    ccmixter_instrumental_audios.append(y)\n",
    "    y,sr = librosa.load(mix_path,sr=None)\n",
    "    ccmixter_complete_audios.append(y)\n",
    "print(str(len(ccmixter_vocal_audios)) + \" Musicas com vocal carregadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mir1k_path = '/home/pedro.lopes/data/dataset/MIR-1K/Wavfile/'\n",
    "%cd $mir1k_path\n",
    "vocal_path = mir1k_path +'amy_8_01.wav'\n",
    "names = glob('*')\n",
    "mir1k_vocal_audios = []\n",
    "mir1k_instrumental_audios = []\n",
    "mir1k_complete_audios = []\n",
    "for name in names:    \n",
    "    y,sr = librosa.load(vocal_path,sr=None,mono=False)\n",
    "    instrumental_audio=y[0]\n",
    "    vocal_audio = y[1]\n",
    "    mir1k_vocal_audios.append(vocal_audio)\n",
    "    mir1k_instrumental_audios.append(instrumental_audio)\n",
    "    mir1k_complete_audios.append(vocal_audio + instrumental_audio)\n",
    "print(sr)\n",
    "print(str(len(mir1k_vocal_audios)) + \" Musicas com vocal carregadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(y[1],rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = resample(np.asfortranarray(mir1k_vocal_audios[0]),16000,44100)\n",
    "ipd.Audio(y,rate = 44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(medley3_complete_audios[0],rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc = mus[0].targets['accompaniment'].audio[:,0] + mus[0].targets['accompaniment'].audio[:,1]\n",
    "vocals = mus[0].targets['vocals'].audio[:,0] + mus[0].targets['vocals'].audio[:,1]\n",
    "al = mus[0].audio[:,0] + mus[0].audio[:,1]\n",
    "#audio1 = mus[0].audio\n",
    "ipd.Audio(al - acc ,rate=mus[0].rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(al,rate=mus[0].rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocals = np.asfortranarray(mir1k_vocal_audios[0])\n",
    "resampled = resample(vocals,16000,8192)\n",
    "ipd.Audio(resampled,rate=8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "7gtjSNO2-5Jn",
    "outputId": "b8bc5a97-2485-490f-aa93-2ffc07de91d2"
   },
   "outputs": [],
   "source": [
    "'''track_list = []\n",
    "vocal_list = []\n",
    "stft_list = []\n",
    "vocal_stft_list = []\n",
    "num_seg = 25\n",
    "num_samples = num_seg*mus[0].rate\n",
    "num_freq = 512\n",
    "shape = (len(mus),num_freq+1,int(np.ceil(num_samples/(2*num_freq))*2+1))\n",
    "stft_list = np.zeros(shape,dtype=complex)\n",
    "vocal_stft_list = np.zeros(shape,dtype=complex)'''\n",
    "\n",
    "'''for i in tqdm(range(len(mus))):\n",
    "    track = mus[i]\n",
    "    interval_start = int(np.random.uniform(0, len(track.audio)-num_samples))\n",
    "    f,t, stft_data = signal.stft(track.audio[interval_start:interval_start + num_samples,0] + track.audio[interval_start:interval_start + num_samples,1], track.rate, nperseg=(2*num_freq),noverlap=num_freq)\n",
    "    #f,t, stft_data = signal.stft(track.audio[:,0] + track.audio[:,1], track.rate, nperseg=(2*num_freq),noverlap=num_freq)\n",
    "    stft_list[i] = stft_data\n",
    "    f,t, vocal_stft =  signal.stft(track.targets['vocals'].audio[interval_start:interval_start + num_samples,0] + track.targets['vocals'].audio[interval_start:interval_start + num_samples,1], track.rate,nperseg=1024,noverlap=512)\n",
    "    #f,t, vocal_stft =  signal.stft(track.targets['vocals'].audio[:,0] + track.targets['vocals'].audio[:,1], track.rate,nperseg=1024,noverlap=512)\n",
    "    f,t, acc_stft = signal.stft(track.targets['accompaniment'].audio[interval_start:interval_start + num_samples,0] + track.targets['accompaniment'].audio[interval_start:interval_start + num_samples,0], track.rate,nperseg=1024,noverlap=512)\n",
    "    vocal_stft_list[i] = vocal_stft\n",
    "'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4s88iXcxYJWV"
   },
   "outputs": [],
   "source": [
    "def append_to_dataset(datapath,dataset_name,new_data):\n",
    "  with h5py.File(datapath, mode='a') as h5f:\n",
    "    dset = h5f[dataset_name]\n",
    "    shape_old = dset.shape\n",
    "    shape_new = list(dset.shape)\n",
    "    shape_new[0] += new_data.shape[0]\n",
    "    shape_new = tuple(shape_new)\n",
    "    dset.resize(shape_new)\n",
    "    #print(shape_old,shape_new)\n",
    "    dset[shape_old[0]:shape_new[0],:] = new_data\n",
    "    h5f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "pqTYQmzlepXg",
    "outputId": "2c94d195-63b8-4206-a700-1f4b6834fb09"
   },
   "outputs": [],
   "source": [
    "hf_train.close()\n",
    "hf_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 904
    },
    "colab_type": "code",
    "id": "UfGViyGjeWlz",
    "outputId": "edd8df4f-fcad-4052-b375-8463e49cb75c"
   },
   "outputs": [],
   "source": [
    "track_list = []\n",
    "vocal_list = []\n",
    "stft_list = []\n",
    "vocal_stft_list = []\n",
    "\n",
    "num_freq = 512\n",
    "%cd ~/pf/code\n",
    "# datapath = '../data/4datasets_16khz_train.h5'\n",
    "# datapath_test = '../data/4datasets_16khz_test.h5'\n",
    "# hf_train = h5py.File(datapath, 'w')\n",
    "# hf_test = h5py.File(datapath_test, 'w')\n",
    "\n",
    "#hf.create_dataset('Y_train_acc',chunks=True,maxshape=(None,513))\n",
    "path = '../norm_data_full.json'\n",
    "norm_data = {}\n",
    "\n",
    "\n",
    "len_others = len(mir1k_complete_audios) + len(ccmixter_complete_audios) + len(medley_complete_audios) + len(medley3_complete_audios)\n",
    "start = 0#len(mus) + len(mir1k_complete_audios) + len(ccmixter_complete_audios) + len(medley_complete_audios)\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    for i in tqdm(range(start,len(mus) + len_others)):\n",
    "    # for i in tqdm(range(start,len(mus))):\n",
    "        rate_down = 44100\n",
    "        mode = 'train'\n",
    "        rate = 44100\n",
    "        if i<100:\n",
    "            acc = mus[i].targets['accompaniment'].audio[:,0] + mus[i].targets['accompaniment'].audio[:,1]\n",
    "            vocals = mus[i].targets['vocals'].audio[:,0] + mus[i].targets['vocals'].audio[:,1]\n",
    "            al = mus[i].audio[:,0] + mus[i].audio[:,1]\n",
    "        if i>=100 and i<150:\n",
    "            acc = mus[i].targets['accompaniment'].audio[:,0] + mus[i].targets['accompaniment'].audio[:,1]\n",
    "            vocals = mus[i].targets['vocals'].audio[:,0] + mus[i].targets['vocals'].audio[:,1]\n",
    "            al = mus[i].audio[:,0] + mus[i].audio[:,1]\n",
    "            mode='test'\n",
    "        if i>=len(mus) and i<(len(mus)+len(mir1k_complete_audios)):\n",
    "            rate = 16000\n",
    "            aux_index = i -len(mus)\n",
    "            acc = mir1k_instrumental_audios[aux_index]\n",
    "            vocals = mir1k_vocal_audios[aux_index]\n",
    "            al = mir1k_complete_audios[aux_index]\n",
    "        if i>=(len(mus)+len(mir1k_complete_audios)) and i<(len(mus)+len(mir1k_complete_audios) + len(ccmixter_complete_audios)):\n",
    "            rate = 44100\n",
    "            aux_index = i - (len(mus)+len(mir1k_complete_audios))\n",
    "            acc = ccmixter_instrumental_audios[aux_index]\n",
    "            vocals = ccmixter_vocal_audios[aux_index]\n",
    "            al = ccmixter_complete_audios[aux_index]\n",
    "        if i>=(len(mus)+len(mir1k_complete_audios) + len(ccmixter_complete_audios)) and i<(len(mus)+len(mir1k_complete_audios) + len(ccmixter_complete_audios) + len(medley_complete_audios)):\n",
    "            aux_index = i - (len(mus)+len(mir1k_complete_audios) + len(ccmixter_complete_audios))\n",
    "            acc = medley_instrumental_audios[aux_index]\n",
    "            vocals = medley_vocal_audios[aux_index]\n",
    "            al = medley_complete_audios[aux_index]\n",
    "        if i>=(len(mus)+len(mir1k_complete_audios) + len(ccmixter_complete_audios) + len(medley_complete_audios)):\n",
    "            aux_index = i - (len(mus)+len(mir1k_complete_audios) + len(ccmixter_complete_audios) + len(medley_complete_audios))\n",
    "            acc = medley3_instrumental_audios[aux_index]\n",
    "            vocals = medley3_vocal_audios[aux_index]\n",
    "            al = medley3_complete_audios[aux_index]\n",
    "        acc = np.asfortranarray(acc)\n",
    "        vocals = np.asfortranarray(vocals)\n",
    "        al = np.asfortranarray(al)\n",
    "        if rate != rate_down:\n",
    "            acc_resampled = resample(acc,rate,rate_down)\n",
    "            vocals_resampled = resample(vocals,rate,rate_down)\n",
    "            al_resampled = resample(al,rate,rate_down)\n",
    "        else:\n",
    "            acc_resampled = acc\n",
    "            vocals_resampled = vocals\n",
    "            al_resampled = al\n",
    "        if mode=='train':\n",
    "            audio_path = '/home/pedro.lopes/data/audio_data/train/'\n",
    "        else:\n",
    "            audio_path = '/home/pedro.lopes/data/audio_data/test/'\n",
    "\n",
    "\n",
    "        audio_acc = acc_resampled\n",
    "        audio_vocals = vocals_resampled\n",
    "        audio_al = al_resampled\n",
    "        librosa.output.write_wav(audio_path + 'sample_' + str(i) + '_vocals.wav',y=audio_vocals,sr=rate_down)\n",
    "        librosa.output.write_wav(audio_path + 'sample_' + str(i) + '_acc.wav',y=audio_acc,sr=rate_down)\n",
    "        librosa.output.write_wav(audio_path + 'sample_' + str(i) + '_mix.wav',y=audio_al,sr=rate_down)\n",
    "\n",
    "#         for j in range(-3,4,1):\n",
    "#             if j==0:\n",
    "#                 audio_acc = acc_resampled\n",
    "#                 audio_vocals = vocals_resampled\n",
    "#                 audio_al = vocals_resampled + acc_resampled\n",
    "#             else:\n",
    "#                 audio_acc = pyrb.pitch_shift(y=acc_resampled,sr=rate_down,n_steps=j,rbargs={'--formant': '-F'})\n",
    "#                 audio_vocals = pyrb.pitch_shift(y=vocals_resampled,sr=rate_down,n_steps=j,rbargs={'--formant': '-F'})\n",
    "#                 audio_al = audio_vocals + audio_acc\n",
    "#             librosa.output.write_wav(audio_path + 'sample_' + str(i) + '_' + str(j) + '_vocals.wav',y=audio_vocals,sr=rate_down)\n",
    "#             librosa.output.write_wav(audio_path + 'sample_' + str(i) + '_' + str(j) + '_acc.wav',y=audio_acc,sr=rate_down)\n",
    "#             librosa.output.write_wav(audio_path + 'sample_' + str(i) + '_' + str(j) + '_mix.wav',y=audio_al,sr=rate_down)\n",
    "#         time_stretches =  [0.5, 0.93, 1, 1.07, 1.15]\n",
    "#         for ts in time_stretches:\n",
    "#             if ts==1:\n",
    "#                 audio_acc = acc_resampled\n",
    "#                 audio_vocals = vocals_resampled\n",
    "#                 audio_al = vocals_resampled + acc_resampled\n",
    "#             else:\n",
    "\n",
    "\n",
    "#                 audio_acc = pyrb.time_stretch(y=acc_resampled,sr=rate_down,rate=ts)\n",
    "#                 audio_vocals = pyrb.time_stretch(y=vocals_resampled,sr=rate_down,rate=ts)\n",
    "#                 audio_al = audio_vocals + audio_acc\n",
    "#             librosa.output.write_wav(audio_path + 'sample_' + str(i) + '_' + str(ts) + 't_vocals.wav',y=audio_vocals,sr=rate_down)\n",
    "#             librosa.output.write_wav(audio_path + 'sample_' + str(i) + '_' + str(ts) + 't_acc.wav',y=audio_acc,sr=rate_down)\n",
    "#             librosa.output.write_wav(audio_path + 'sample_' + str(i) + '_' + str(ts) + 't_mix.wav',y=audio_al,sr=rate_down)\n",
    "\n",
    "\n",
    "    #     acc_resampled_shifted = get_audio_with_shifts(acc_resampled,rate_down)\n",
    "    #     vocals_resampled_shifted = get_audio_with_shifts(vocals_resampled,rate_down)\n",
    "    #     al_resampled_shifted = get_audio_with_shifts(al_resampled,rate_down)\n",
    "\n",
    "    #     _,_,stft_data = signal.stft(al_resampled, rate_down, nperseg=(2*num_freq),noverlap=num_freq) # lembrar que a função cospe f,t, data\n",
    "    #     #f,t, stft_data = signal.stft(track.audio[:,0] + track.audio[:,1], track.rate, nperseg=(2*num_freq),noverlap=num_freq)\n",
    "    #     _,_,acc_stft = signal.stft(acc_resampled, rate_down,nperseg=1024,noverlap=512)\n",
    "    #     _,_,vocal_stft =  signal.stft(vocals_resampled, rate_down,nperseg=1024,noverlap=512)\n",
    "    #     if i==0:\n",
    "    #         hf_train.create_dataset('X_train',chunks=True,maxshape=(None,513),data=stft_data.T)\n",
    "    #         hf_train.create_dataset('Y_train_vocal',chunks=True,maxshape=(None,513),data=vocal_stft.T)\n",
    "    #         hf_train.create_dataset('Y_train_acc',chunks=True,maxshape=(None,513),data=acc_stft.T)\n",
    "\n",
    "    #         norm_data['X_max'] = 0\n",
    "    #         norm_data['X_min'] = 1000\n",
    "    #         with open(path, 'w') as fp:\n",
    "    #           json.dump(norm_data, fp)\n",
    "    #         hf_train.close()\n",
    "    #     if i==100:\n",
    "    #         hf_test.create_dataset('X_test',chunks=True,maxshape=(None,513),data=stft_data.T)\n",
    "    #         hf_test.create_dataset('Y_test_vocal',chunks=True,maxshape=(None,513),data=vocal_stft.T)\n",
    "    #         hf_test.create_dataset('Y_test_acc',chunks=True,maxshape=(None,513),data=acc_stft.T)\n",
    "    #         hf_test.close()\n",
    "\n",
    "\n",
    "    #     if mode == 'train':\n",
    "    #         append_to_dataset(datapath=datapath,dataset_name='X_train',new_data=stft_data.T)\n",
    "    #         append_to_dataset(datapath=datapath,dataset_name='Y_train_vocal',new_data=vocal_stft.T)\n",
    "    #         append_to_dataset(datapath=datapath,dataset_name='Y_train_acc',new_data=acc_stft.T)\n",
    "    #         if(np.max(np.abs(stft_data[2]))>=norm_data['X_max']):\n",
    "    #             norm_data['X_max'] = np.log(np.max(np.abs(stft_data))+1e-7)\n",
    "    #         with open(path, 'w') as fp:\n",
    "    #             json.dump(norm_data, fp)\n",
    "    #         if(np.min(np.abs(stft_data[2]))<=norm_data['X_min']):\n",
    "    #             norm_data['X_min'] = np.log(np.min(np.abs(stft_data))+1e-7)\n",
    "    #         with open(path, 'w') as fp:\n",
    "    #             json.dump(norm_data, fp)\n",
    "    #     else:\n",
    "    #         append_to_dataset(datapath=datapath_test,dataset_name='X_test',new_data=stft_data.T)\n",
    "    #         append_to_dataset(datapath=datapath_test,dataset_name='Y_test_vocal',new_data=vocal_stft.T)\n",
    "    #         append_to_dataset(datapath=datapath_test,dataset_name='Y_test_acc',new_data=acc_stft.T)\n",
    "\n",
    "    #     #vocal_stft_list[i] = vocal_stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,sr = librosa.load(audio_path + 'sample_' + str(1) + '_vocals.wav',sr=None,mono=False)\n",
    "f,t,stft_data = signal.stft(y)\n",
    "plt.pcolormesh(np.log(np.abs(stft_data)+1e-7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(y,sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5 = h5py.File(datapath, 'r')\n",
    "json_path = '../len_full_samples.json'\n",
    "X_train_true = h5.get('X_train')\n",
    "train_len = {}\n",
    "train_len['len'] = X_train_true.shape\n",
    "with open(json_path, 'w') as fp:\n",
    "    json.dump(train_len, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5h1t5tKDLOht"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "norm_data = {}\n",
    "norm_data['X_max'] = max_X_train\n",
    "norm_data['X_min'] = min_X_train\n",
    "path = '/content/drive/My Drive/Projeto Final/data/norm_data_full.json' \n",
    "with open(path, 'w') as fp:\n",
    "    json.dump(norm_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "wK_zJTsYhAnp",
    "outputId": "43087d26-af75-48a7-823f-c01b8a3113de"
   },
   "outputs": [],
   "source": [
    "hf = h5py.File(datapath, 'r')\n",
    "plt.pcolormesh(np.abs(np.log(hf['X_train'][0:128].T+1e-8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K7Qs-tF1gLVW"
   },
   "outputs": [],
   "source": [
    "stft_list = np.hstack(stft_list).T\n",
    "vocal_stft_list = np.hstack(vocal_stft_list).T\n",
    "acc_stft_list = np.hstack(acc_stft_list).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yavkezlRIqtJ"
   },
   "outputs": [],
   "source": [
    "teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XSyrLvKbLpXS"
   },
   "outputs": [],
   "source": [
    "ipd.Audio(track.audio[0:num_samples,0],rate=mus[0].rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pM0L70-969n9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "num_seg = 10\n",
    "num_samples = num_seg*mus[0].rate\n",
    "f,t, stft_data = signal.stft(mus[0].targets['vocals'].audio[0:num_samples,0] + mus[0].targets['vocals'].audio[0:num_samples,1], mus[0].rate,nperseg=1024,noverlap=512)\n",
    "print(len(stft_data[1]))\n",
    "\n",
    "i = 3\n",
    "\n",
    "freq_bins = 513\n",
    "plt.pcolormesh(t, f, np.log(np.abs(stft_data)+1e-30),cmap=cm.gray)\n",
    "xmin =0\n",
    "xmax =10\n",
    "ymin =0\n",
    "ymax = 20000\n",
    "\n",
    "plt.axis([xmin, xmax, ymin, ymax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4vcGMQ8gLXD"
   },
   "outputs": [],
   "source": [
    "\n",
    "hf = h5py.File('/content/drive/My Drive/Projeto Final/data/data_context_2stems.h5', 'w')\n",
    "\n",
    "\n",
    "hf.create_dataset('X_train', data=stft_list)\n",
    "hf.create_dataset('Y_train_vocal', data=vocal_stft_list)\n",
    "hf.create_dataset('Y_train_acc', data=acc_stft_list)\n",
    "\n",
    "hf.close()\n",
    "path = '/content/drive/My Drive/Projeto Final/data/len_raw.npy' \n",
    "np.save(path,len(stft_list))\n",
    "\n",
    "print('terminei!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ToEmTF0eZiVu"
   },
   "outputs": [],
   "source": [
    "def normalize(x,save=False):\n",
    "    scaled_x = (x - np.mean(x))/(np.abs(np.std(x))+1e-8)\n",
    "\n",
    "    if save:\n",
    "      return scaled_x, np.mean(x), np.std(x)\n",
    "    #scaled_x = scaled_x - np.mean(scaled_x)\n",
    "    return scaled_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-N1Pn8cGWA2T"
   },
   "outputs": [],
   "source": [
    "def normalize_01(x,save=False):\n",
    "    scaled_x = (x - np.min(x))/(np.max(x) - np.min(x)+1e-8)\n",
    "\n",
    "    if save:\n",
    "      return scaled_x, np.min(x), np.max(x)\n",
    "    #scaled_x = scaled_x - np.mean(scaled_x)\n",
    "    return scaled_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NSqhwhPlbc82",
    "outputId": "d1c2d1cf-9f36-4c7a-bfca-d0823a3b3125"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "h5 = h5py.File('/content/drive/My Drive/Projeto Final/data/data_context.h5', 'r')\n",
    "X_train_true = h5.get('X_train')\n",
    "X_train_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W6GIBv9Ncoha",
    "outputId": "fcb1e00e-5640-4168-d252-2dc03ea3002c"
   },
   "outputs": [],
   "source": [
    "X_train_true[0:500].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CAG8dHcTc1v7",
    "outputId": "ff3279ec-2813-493c-b40f-8cca8840b0ae"
   },
   "outputs": [],
   "source": [
    "append_to_dataset('test.h5','X_train',X_train_true[500:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "1tq8j1GodMbE",
    "outputId": "f060b60e-1200-4400-92d2-7cbbb720b17a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "id": "bTtT-C-fZuM8",
    "outputId": "cf7b84b0-0754-4a13-c0b4-51f5e1b81dd2"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "norm_data ={}\n",
    "\n",
    "h5 = h5py.File('/content/drive/My Drive/Projeto Final/data/full_context.h5', 'r')\n",
    "\n",
    "# X_normal,norm_data['X_mean'],norm_data['X_std'] = normalize(np.log(np.abs(h5.get('X_train'))+1e-7),save =True)\n",
    "# y_normal,norm_data['y_mean'],norm_data['y_std'] = normalize(np.log(np.abs(h5.get('Y_train'))+1e-7),save = True)\n",
    "# hf = h5py.File('/content/drive/My Drive/Projeto Final/data/data_normalized_mean.h5', 'w')\n",
    "\n",
    "\n",
    "print(np.min(h5.get('X_train')))\n",
    "\n",
    "# hf.create_dataset('X_train', data=X_normal)\n",
    "# hf.create_dataset('Y_train', data=y_normal)\n",
    "\n",
    "hf.close()\n",
    "h5.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elwkuWcCVZq4"
   },
   "outputs": [],
   "source": [
    "path = '/content/drive/My Drive/Projeto Final/data/norm_data_mean.json' \n",
    "with open(path, 'w') as fp:\n",
    "    json.dump(norm_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQ2_XNV4MYyL"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "norm_data ={}\n",
    "\n",
    "h5 = h5py.File('/content/drive/My Drive/Projeto Final/data/full_context.h5', 'r')\n",
    "\n",
    "X_normal,norm_data['X_min'],norm_data['X_max'] = normalize_01(np.log(np.abs(h5.get('X_train'))+1e-7),save =True)\n",
    "y_vocal_normal,norm_data['y_max_voc'],norm_data['y_min_voc'] = normalize_01(np.log(np.abs(h5.get('Y_train_vocal'))+1e-7),save = True)\n",
    "#y_acc_normal,norm_data['y_max_acc'],norm_data['y_min_acc'] = normalize_01(np.log(np.abs(h5.get('Y_train_acc'))+1e-7),save = True)\n",
    "hf = h5py.File('/content/drive/My Drive/Projeto Final/data/data_normalized_01_full.h5', 'w')\n",
    "\n",
    "\n",
    "hf.create_dataset('X_train', data=X_normal)\n",
    "hf.create_dataset('Y_train_vocal', data=y_vocal_normal)\n",
    "#hf.create_dataset('Y_train_acc', data=y_acc_normal)\n",
    "\n",
    "hf.close()\n",
    "h5.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hcaqdIFfMcZb"
   },
   "outputs": [],
   "source": [
    "path = '/content/drive/My Drive/Projeto Final/data/norm_data_01.json' \n",
    "with open(path, 'w') as fp:\n",
    "    json.dump(norm_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HaxokRYuutfK"
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, batch_size=32, dim=(32,32,32), n_channels=1,\n",
    "                shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.path = ''\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = np.array(np.log(np.abs(X_train[ID])+1e-10)).reshape((*self.dim, self.n_channels))\n",
    "            X[i,] = X[i,]\n",
    "            # Store class\n",
    "            y[i] = np.log(np.abs(Y_train[ID])+1e-10)\n",
    "        \n",
    "        X = normalize(X)\n",
    "        y = normalize(y)\n",
    "\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lBBrkPL0oPdo"
   },
   "outputs": [],
   "source": [
    "train_data_groups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tdo8NIabs2N6"
   },
   "outputs": [],
   "source": [
    "target_groups[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wb4q-hId3Vj4"
   },
   "outputs": [],
   "source": [
    "a = train_data_groups\n",
    "\n",
    "plt.pcolormesh(t[i:i+sample_len], f, np.abs(a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udt6e6AUsr8E"
   },
   "outputs": [],
   "source": [
    "plt.pcolormesh(np.abs(teste[:,0:863]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gMNOPd5YtPHD"
   },
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sK0kGLb2xLsh"
   },
   "outputs": [],
   "source": [
    "num_samples/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MJmeQ0DsD6on"
   },
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(16, (3,3), padding='same', input_shape=(freq_bins, sample_len, 1)))\n",
    "  model.add(LeakyReLU())\n",
    "  model.add(Conv2D(16, (3,3), padding='same'))\n",
    "  model.add(LeakyReLU())\n",
    "  model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Conv2D(16, (3,3), padding='same'))\n",
    "  model.add(LeakyReLU())\n",
    "  model.add(Conv2D(16, (3,3), padding='same'))\n",
    "  model.add(LeakyReLU())\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(64))\n",
    "  model.add(LeakyReLU())\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(freq_bins, activation='relu'))\n",
    "  model.compile(loss=keras.losses.mse, optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GnPXsFAI_GAJ"
   },
   "outputs": [],
   "source": [
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "  history = model.fit(np.abs(train_data_groups).reshape(target_groups.shape[0],freq_bins,sample_len,1),np.abs(target_groups),batch_size = 32,epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xXmnyd4-gLXh"
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z5bQx4qlAISj"
   },
   "outputs": [],
   "source": [
    "a = model.predict(np.abs(train_data_groups[0:1*len(stft_list[0][0])].reshape(len(stft_list[0][0]),513,11,1)))\n",
    "test = np.transpose(a)\n",
    "test_list = []\n",
    "for i in range(len(test)):\n",
    "  test_list.append(np.roll(test[i],2))\n",
    "test = np.array(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PXRD0-Wj5Prs"
   },
   "outputs": [],
   "source": [
    "len(stft_list[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-xiKu0n1_2-w"
   },
   "outputs": [],
   "source": [
    "result_stft = np.multiply(test,stft_list[0])\n",
    "plt.pcolormesh(t, f, np.abs(result_stft))\n",
    "xmin =0\n",
    "xmax = 3\n",
    "ymin =0\n",
    "ymax = 3000\n",
    "\n",
    "plt.axis([xmin, xmax, ymin, ymax])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3D6LZw6GFp9I"
   },
   "outputs": [],
   "source": [
    "plt.pcolormesh(t, f, np.abs(vocal_stft_list[2]))\n",
    "xmin =0\n",
    "xmax = 30\n",
    "ymin =0\n",
    "ymax = 3000\n",
    "\n",
    "plt.axis([xmin, xmax, ymin, ymax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0yGidBR6rXQ"
   },
   "outputs": [],
   "source": [
    "audio1 = signal.istft(vocal_stft_list[863:863*2].T,fs =mus[0].rate)\n",
    "audio1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBLni4gQ7Hxx"
   },
   "outputs": [],
   "source": [
    "ipd.Audio(audio1[1],rate=mus[0].rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V6eoYANz-zgY"
   },
   "outputs": [],
   "source": [
    "ipd.Audio(mus[10].audio[:,0] + mus[10].audio[:,1],rate=mus[0].rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4uKrO933gLX9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "gen_dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:dev_pedro] *",
   "language": "python",
   "name": "conda-env-dev_pedro-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
